# *_Regularization_*



## **_Resources._** ðŸ‘Œ 

 

### **_Read or watch:_**  ðŸ‘ˆ


>> * [Regularization (mathematics)](https://intranet.hbtn.io/rltoken/G22TZHYwwb0PwlAuEZdDEQ)
>> * [An Overview of Regularization Techniques in Deep Learning ](https://intranet.hbtn.io/rltoken/Mao_NUBBiwm0Qh8b-axAgw)
>> * [L2 Regularization and Back-Propagation](https://intranet.hbtn.io/rltoken/AY80ruaSMDL_AGnjZOpWGQ)
>> * [Intuitions on L1 and L2 Regularisation](https://intranet.hbtn.io/rltoken/P_MpN-p1RsvtpWV6xAmpOw) 
>> * [Analysis of Dropout](https://intranet.hbtn.io/rltoken/huRNIkxWr5OV1Tit658LcQ)
>> * [Early stopping](https://intranet.hbtn.io/rltoken/4YMCmw41ovvYtMvr-Wl7LA)
>> * [How to use early stopping properly for training deep neural network?](https://intranet.hbtn.io/rltoken/t6UPkGJXD_nK7TfGwE9Rig)
>> * [Data Augmentation | How to use Deep Learning when you have Limited Dataâ€Š](https://intranet.hbtn.io/rltoken/MaLMSTSCPux71mW1RIhiBA)
>> * [deeplearning.ai ](https://intranet.hbtn.io/rltoken/GriJE79Gr4BF8HG2DGpbYg)
>> * [Regularization](https://intranet.hbtn.io/rltoken/BJoxOnJN-GJyZ_fJ9qT0EQ)
>> * [Why Regularization Reduces Overfitting](https://intranet.hbtn.io/rltoken/dLdv5Gi77DmWNyR3MHe69g)
>> * [Dropout Regularization](https://intranet.hbtn.io/rltoken/23ue4EQxNd9LOCW0Q6FNNQ)
>> * [Understanding Dropout](https://intranet.hbtn.io/rltoken/eleB8ZvoJiOltULeHkDvGQ)
>> * [Other Regularization Methods](https://intranet.hbtn.io/rltoken/QuFgq0_MKTGq6UAKj5OjEw)

##Â· **_References_**  ðŸ‘ˆ

>> * [numpy.linalg.norm](https://intranet.hbtn.io/rltoken/5YoCQBn6-nRyuldXYANpuw)
>> * [numpy.random.binomial](https://intranet.hbtn.io/rltoken/vdPHIWg_6Dq6-e6Wvjmz9w)
>> * [tf.keras.regularizers.L2](https://intranet.hbtn.io/rltoken/y9OSDn67_DpM5hlMXe116Q)
>> * [tf.layers.Dense](https://intranet.hbtn.io/rltoken/K0y9uk5aa5uzLsyavooezg)
>> * [tf.losses.get_regularization_loss](https://intranet.hbtn.io/rltoken/R0pALpDYtCoQulGJDTE52A)
>> * [tf.layers.Dropout](https://intranet.hbtn.io/rltoken/VzdLxZHGgNTASxpaeyymDA)
>> * [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://intranet.hbtn.io/rltoken/2jIHjQpd_A2-4IF1SbL5dg)
>> * [Early Stopping - but when?](https://intranet.hbtn.io/rltoken/b_knZ8MqBEHA3TPoGruYGw)
>> * [L2 Regularization versus Batch and Weight Normalization](https://intranet.hbtn.io/rltoken/JVvKoC0p-wBoLl3qF7xChQ)


## **_Built with:_** ðŸ› ï¸

>> * Ubuntu 20.04 LTS
>> 
>> * Emacs editor && Pycharm
>> 
>> * TensorFlow (version 2.6.0) 
>> 
>> * $ pip install --user tensorflow==2.6
>> 
>> * pycodestyle (version 2.6)
>> 
>> * When initializing layer weights, use tf.keras.initializers.VarianceScaling(scale=2.0, mode=("fan_avg")).
